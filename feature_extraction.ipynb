{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_9256\\1100877095.py\", line 2, in <module>\n",
      "    import spacy\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\thinc\\types.py\", line 25, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\thinc\\compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\__init__.py\", line 2120, in <module>\n",
      "    from torch._higher_order_ops import cond\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_higher_order_ops\\__init__.py\", line 1, in <module>\n",
      "    from .cond import cond\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_higher_order_ops\\cond.py\", line 5, in <module>\n",
      "    import torch._subclasses.functional_tensor\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 42, in <module>\n",
      "    class FunctionalTensor(torch.Tensor):\n",
      "  File \"C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 258, in FunctionalTensor\n",
      "    cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 1583: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m input_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompiled_output.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Path to your compiled output CSV file\u001b[39;00m\n\u001b[0;32m     84\u001b[0m output_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextracted_features.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Path to the output CSV with features\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m \u001b[43mprocess_and_extract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 69\u001b[0m, in \u001b[0;36mprocess_and_extract_features\u001b[1;34m(input_csv, output_csv)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(input_csv, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[0;32m     68\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(infile)\n\u001b[1;32m---> 69\u001b[0m     header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Skip the header row\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(reader)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Open the output CSV to write features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 1583: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example list of agreement and disagreement lexicons\n",
    "agreement_lexicon = ['agree', 'agreeing', 'support', 'supporting', 'in favor of', 'yes', 'yes', 'certainly', 'definitely', 'sure']\n",
    "disagreement_lexicon = ['disagree', 'disagreeing', 'oppose', 'opposing', 'against', 'no', 'not', 'never', 'certainly not', 'definitely not']\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "# 1. N-gram generation\n",
    "def generate_ngrams(text, n=1):\n",
    "    tokens = nltk.word_tokenize(text.lower())  # Tokenize and lowercase\n",
    "    return list(ngrams(tokens, n))\n",
    "\n",
    "# 2. Extract Modal Verbs using spaCy\n",
    "def extract_modal_verbs(text):\n",
    "    doc = nlp(text)\n",
    "    modal_verbs = [token.text for token in doc if token.tag_ == 'MD']  # Modal verbs in spaCy are tagged as 'MD'\n",
    "    return ' '.join(modal_verbs)\n",
    "\n",
    "# 3. Detect Negations\n",
    "def detect_negation(text):\n",
    "    doc = nlp(text)\n",
    "    negations = [token.text for token in doc if token.dep_ == 'neg']\n",
    "    return ' '.join(negations)\n",
    "\n",
    "# 4. Argument lexicon match (agreement and disagreement)\n",
    "def check_argument_lexicon(text):\n",
    "    tokens = text.lower().split()\n",
    "    agreement_count = sum(1 for word in tokens if word in agreement_lexicon)\n",
    "    disagreement_count = sum(1 for word in tokens if word in disagreement_lexicon)\n",
    "    return agreement_count, disagreement_count\n",
    "\n",
    "# 5. Generate feature vector\n",
    "def extract_features(text, label):\n",
    "    # 1. N-grams (Unigrams, Bigrams, Trigrams)\n",
    "    unigrams = generate_ngrams(text, n=1)\n",
    "    bigrams = generate_ngrams(text, n=2)\n",
    "    trigrams = generate_ngrams(text, n=3)\n",
    "\n",
    "    # Flatten the ngrams into strings\n",
    "    unigram_str = ' '.join(['_'.join(gram) for gram in unigrams])\n",
    "    bigram_str = ' '.join(['_'.join(gram) for gram in bigrams])\n",
    "    trigram_str = ' '.join(['_'.join(gram) for gram in trigrams])\n",
    "\n",
    "    # 2. Argument lexicons (agreement and disagreement)\n",
    "    agreement_count, disagreement_count = check_argument_lexicon(text)\n",
    "\n",
    "    # 3. Modal verbs\n",
    "    modals = extract_modal_verbs(text)\n",
    "\n",
    "    # 4. Negations\n",
    "    negations = detect_negation(text)\n",
    "\n",
    "    # Return the feature vector\n",
    "    return [text, label, unigram_str, bigram_str, trigram_str, agreement_count, disagreement_count, modals, negations]\n",
    "\n",
    "# Function to process compiled_output.csv and extract features\n",
    "def process_and_extract_features(input_csv, output_csv):\n",
    "    with open(input_csv, 'r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        header = next(reader)  # Skip the header row\n",
    "        data = list(reader)\n",
    "    \n",
    "    # Open the output CSV to write features\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(['Text', 'Label', 'Unigrams', 'Bigrams', 'Trigrams', 'Agreement_Count', 'Disagreement_Count', 'Modal_Verbs', 'Negations'])\n",
    "        \n",
    "        for row in data:\n",
    "            text, label = row\n",
    "            features = extract_features(text, label)\n",
    "            writer.writerow(features)\n",
    "\n",
    "# Example usage\n",
    "input_csv = 'compiled_output.csv'  # Path to your compiled output CSV file\n",
    "output_csv = 'extracted_features.csv'  # Path to the output CSV with features\n",
    "\n",
    "process_and_extract_features(input_csv, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
